import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sentence_transformers import util
from utils import (
    preprocess_text, read_uploaded_file_bytes, parse_topics_field, simple_flags,
    pos_first_token, encode_texts_in_batches, jaccard_tokens, style_suspicious_and_low,
    bootstrap_diff_ci, load_model_from_source
)

# ============== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ==============
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤", layout="wide")
st.title("üìä –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")

# ============== –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ==============
st.sidebar.header("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
uploaded = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/Excel/JSON", type=["csv", "xlsx", "json", "ndjson"])

# ============== –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ==============
if uploaded:
    try:
        df, file_hash = read_uploaded_file_bytes(uploaded)
        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫.")
        st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:")
        st.dataframe(df.head())
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        st.stop()

    # ===== –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ =====
    st.sidebar.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª–æ–Ω–æ–∫")
    col_answer = st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å –æ—Ç–≤–µ—Ç–∞–º–∏", df.columns)
    col_topics = st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å —Ç–µ–º–∞–º–∏", df.columns)

    # ===== –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ =====
    st.sidebar.subheader("–ú–æ–¥–µ–ª—å")
    model_source = st.sidebar.radio("–ò—Å—Ç–æ—á–Ω–∏–∫ –º–æ–¥–µ–ª–∏", ["huggingface", "google_drive"])
    model_id = st.sidebar.text_input("ID –∏–ª–∏ –∏–º—è –º–æ–¥–µ–ª–∏", value="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # ===== –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ =====
    if st.sidebar.button("–í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑"):
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏..."):
            model = load_model_from_source(model_source, model_id)

        st.subheader("üì• –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        df["_answer_clean"] = df[col_answer].apply(preprocess_text)
        df["_topics_list"] = df[col_topics].apply(parse_topics_field)
        df["_topic_main"] = df["_topics_list"].apply(lambda lst: lst[0] if lst else "")

        # ===== –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ =====
        st.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        embeddings = encode_texts_in_batches(model, df["_answer_clean"].tolist())

        # ===== –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –∏ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ =====
        st.info("–ü–æ–¥—Å—á—ë—Ç –ª–µ–∫—Å–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        df["_neg"] = df["_answer_clean"].apply(lambda t: simple_flags(t)["has_neg"])
        df["_num"] = df["_answer_clean"].apply(lambda t: simple_flags(t)["has_num"])
        df["_len_char"] = df["_answer_clean"].apply(lambda t: simple_flags(t)["len_char"])
        df["_len_tok"] = df["_answer_clean"].apply(lambda t: simple_flags(t)["len_tok"])
        df["_pos_first"] = df["_answer_clean"].apply(pos_first_token)

        # ===== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º (–µ—Å–ª–∏ –µ—Å—Ç—å) =====
        st.subheader("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏")
        topic_groups = df.groupby("_topic_main")
        result_rows = []
        for topic, group in topic_groups:
            if len(group) < 2:
                continue
            idxs = group.index.tolist()
            for i in range(len(idxs)):
                for j in range(i+1, len(idxs)):
                    a_idx, b_idx = idxs[i], idxs[j]
                    emb_a, emb_b = embeddings[a_idx], embeddings[b_idx]
                    sem_score = float(util.cos_sim(emb_a, emb_b))
                    lex_score = jaccard_tokens(df["_answer_clean"].iloc[a_idx], df["_answer_clean"].iloc[b_idx])
                    result_rows.append({
                        "topic": topic,
                        "id_a": a_idx,
                        "id_b": b_idx,
                        "answer_a": df[col_answer].iloc[a_idx],
                        "answer_b": df[col_answer].iloc[b_idx],
                        "score": sem_score,
                        "lexical_score": lex_score
                    })
        if not result_rows:
            st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
            st.stop()
        sim_df = pd.DataFrame(result_rows)

        st.write("–¢–∞–±–ª–∏—Ü–∞ –ø–∞—Ä–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π:")
        st.dataframe(sim_df.head(20))

        # ===== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞–º =====
        st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞–º")
        agg = sim_df.groupby("topic")["score"].mean().reset_index().rename(columns={"score": "mean_score"})
        chart = alt.Chart(agg).mark_bar().encode(
            x="topic",
            y="mean_score",
            tooltip=["topic", "mean_score"]
        ).properties(width=700, height=400)
        st.altair_chart(chart)

        # ===== –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä =====
        st.subheader("‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã")
        sem_thresh = st.slider("–ü–æ—Ä–æ–≥ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏", 0.7, 1.0, 0.85, 0.01)
        lex_thresh = st.slider("–ú–∞–∫—Å. –ª–µ–∫—Å–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å", 0.0, 0.5, 0.2, 0.01)
        low_score_thresh = st.slider("–ü–æ—Ä–æ–≥ –Ω–∏–∑–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏", 0.0, 1.0, 0.4, 0.01)

        st.write("–ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å—Ç—Ä–æ–∫:")
        styled = style_suspicious_and_low(sim_df, sem_thresh, lex_thresh, low_score_thresh)
        st.dataframe(styled, use_container_width=True)

        # ===== –ë—É—Ç—Å—Ç—Ä—ç–ø-–∞–Ω–∞–ª–∏–∑ =====
        st.subheader("üìä Bootstrap-–∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –ø–æ —Ç–µ–º–∞–º")
        topics = sim_df["topic"].unique().tolist()
        if len(topics) >= 2:
            t1 = st.selectbox("–¢–µ–º–∞ 1", topics, index=0)
            t2 = st.selectbox("–¢–µ–º–∞ 2", topics, index=1)
            arr1 = sim_df.loc[sim_df["topic"] == t1, "score"].values
            arr2 = sim_df.loc[sim_df["topic"] == t2, "score"].values
            diff, low, high = bootstrap_diff_ci(arr1, arr2)
            st.write(f"–°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: {diff:.4f}, 95% CI: [{low:.4f}, {high:.4f}]")
        else:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–º –¥–ª—è –±—É—Ç—Å—Ç—Ä—ç–ø-–∞–Ω–∞–ª–∏–∑–∞.")
