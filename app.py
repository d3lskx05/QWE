import streamlit as st

# ===================== –°—Ç—Ä–∞–Ω–∏—Ü–∞ =====================
st.set_page_config(page_title="AI Analyzer", layout="wide")
st.title("üß† AI Analyzer")

# ===================== –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ä–µ–∂–∏–º–æ–≤ =====================
mode = st.sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:",
    ["–†–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏", "–†–∞–±–æ—Ç–∞ —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"],
    index=0
)

# ===================== –†–ï–ñ–ò–ú: –¢–ï–ö–°–¢–û–í–´–ï –ú–û–î–ï–õ–ò =====================
if mode == "–†–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏":
    import altair as alt
    import pandas as pd
    import numpy as np
    import json
    from typing import List

    # –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º
    from utils import (
        preprocess_text,
        parse_topics_field,
        jaccard_tokens,
        style_suspicious_and_low,
        simple_flags,
        pos_first_token,
        load_model_from_source,
        encode_texts_in_batches,
        bootstrap_diff_ci,
        _MORPH,
    )

    from sentence_transformers import util  # –Ω—É–∂–µ–Ω –¥–ª—è cos_sim

    # ===================== –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ =====================
    DEFAULT_HF = "sentence-transformers/all-MiniLM-L6-v2"
    HISTORY_MAX = 500  # –ª–∏–º–∏—Ç –Ω–∞ –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑—Ä–∞—Å—Ç–∞–ª–∞—Å—å

    st.header("üîé Synonym Checker")

    # ===================== –°–∞–π–¥–±–∞—Ä: –ú–æ–¥–µ–ª–∏ =====================
    st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
    model_source = st.sidebar.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ –º–æ–¥–µ–ª–∏", ["huggingface", "google_drive"], index=0)
    if model_source == "huggingface":
        model_id = st.sidebar.text_input("Hugging Face Model ID", value=DEFAULT_HF)
    else:
        model_id = st.sidebar.text_input("Google Drive File ID", value="1RR15OMLj9vfSrVa1HN-dRU-4LbkdbRRf")

    enable_ab_test = st.sidebar.checkbox("–í–∫–ª—é—á–∏—Ç—å A/B —Ç–µ—Å—Ç –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π", value=False)
    if enable_ab_test:
        ab_model_source = st.sidebar.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏", ["huggingface", "google_drive"], index=0, key="ab_source")
        if ab_model_source == "huggingface":
            ab_model_id = st.sidebar.text_input("Hugging Face Model ID (B)", value="sentence-transformers/all-mpnet-base-v2", key="ab_id")
        else:
            ab_model_id = st.sidebar.text_input("Google Drive File ID (B)", value="", key="ab_id")
    else:
        ab_model_id = ""

    batch_size = st.sidebar.number_input("Batch size –¥–ª—è —ç–Ω–∫–æ–¥–∏–Ω–≥–∞", min_value=8, max_value=1024, value=64, step=8)

    # ===================== –°–∞–π–¥–±–∞—Ä: –î–µ—Ç–µ–∫—Ç–æ—Ä =====================
    st.sidebar.header("–î–µ—Ç–µ–∫—Ç–æ—Ä –Ω–µ–æ—á–µ–≤–∏–¥–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
    enable_detector = st.sidebar.checkbox("–í–∫–ª—é—á–∏—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä (high sem, low lex)", value=True)
    semantic_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ (>=)", 0.0, 1.0, 0.80, 0.01)
    lexical_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–π –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ (<=)", 0.0, 1.0, 0.30, 0.01)
    low_score_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ –Ω–∏–∑–∫–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏", 0.0, 1.0, 0.75, 0.01)

    # ===================== –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π =====================
    try:
        with st.spinner("–ó–∞–≥—Ä—É–∂–∞—é –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å..."):
            model_a = load_model_from_source(model_source, model_id)
        st.sidebar.success("–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    except Exception as e:
        st.sidebar.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å: {e}")
        st.stop()

    model_b = None
    if enable_ab_test:
        if ab_model_id.strip() == "":
            st.sidebar.warning("–í–≤–µ–¥–∏—Ç–µ ID –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏")
        else:
            try:
                with st.spinner("–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å B..."):
                    model_b = load_model_from_source(ab_model_source, ab_model_id)
                st.sidebar.success("–ú–æ–¥–µ–ª—å B –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                st.sidebar.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å B: {e}")
                st.stop()

    # ===================== –°–æ—Å—Ç–æ—è–Ω–∏—è =====================
    if "history" not in st.session_state:
        st.session_state["history"] = []
    if "suggestions" not in st.session_state:
        st.session_state["suggestions"] = []

    def add_to_history(record: dict):
        st.session_state["history"].append(record)
        # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        if len(st.session_state["history"]) > HISTORY_MAX:
            st.session_state["history"] = st.session_state["history"][-HISTORY_MAX:]

    def clear_history():
        st.session_state["history"] = []

    def add_suggestions(phrases: List[str]):
        s = [p for p in phrases if p and isinstance(p, str)]
        for p in reversed(s):
            if p not in st.session_state["suggestions"]:
                st.session_state["suggestions"].insert(0, p)
        st.session_state["suggestions"] = st.session_state["suggestions"][:200]

    # ===================== –ò—Å—Ç–æ—Ä–∏—è –≤ —Å–∞–π–¥–±–∞—Ä–µ =====================
    st.sidebar.header("–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫")
    if st.sidebar.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        clear_history()

    if st.session_state["history"]:
        history_bytes = json.dumps(st.session_state["history"], indent=2, ensure_ascii=False).encode('utf-8')
        st.sidebar.download_button("–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é (JSON)", data=history_bytes, file_name="history.json", mime="application/json")
    else:
        st.sidebar.caption("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞—è")

    # ===================== –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–º c –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º =====================
    if "mode" not in st.session_state:
        st.session_state.mode = "–§–∞–π–ª (CSV/XLSX/JSON)"
    if "pending_mode" not in st.session_state:
        st.session_state.pending_mode = None
    if "pending_confirm" not in st.session_state:
        st.session_state.pending_confirm = False
    if "mode_ui_v" not in st.session_state:
        st.session_state.mode_ui_v = 0

    radio_key = f"mode_selector_{st.session_state.mode}_{st.session_state.mode_ui_v}"
    mode_choice = st.radio(
        "–†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏",
        ["–§–∞–π–ª (CSV/XLSX/JSON)", "–†—É—á–Ω–æ–π –≤–≤–æ–¥"],
        index=0 if st.session_state.mode == "–§–∞–π–ª (CSV/XLSX/JSON)" else 1,
        horizontal=True,
        key=radio_key
    )

    if st.session_state.pending_mode is None and mode_choice != st.session_state.mode:
        st.session_state.pending_mode = mode_choice
        st.session_state.pending_confirm = False

    if st.session_state.pending_mode:
        col_warn, col_yes, col_close = st.columns([4, 1, 0.6])
        with col_warn:
            st.warning(
                f"–ü–µ—Ä–µ–π—Ç–∏ –≤ —Ä–µ–∂–∏–º **{st.session_state.pending_mode}**? "
                "–¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã."
            )
        with col_yes:
            if st.button("‚úÖ –î–∞"):
                if not st.session_state.pending_confirm:
                    st.session_state.pending_confirm = True
                    st.info("–ù–∞–∂–º–∏—Ç–µ ‚úÖ –µ—â—ë —Ä–∞–∑ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è")
                else:
                    st.session_state.mode = st.session_state.pending_mode
                    st.session_state.pending_mode = None
                    st.session_state.pending_confirm = False
                    for k in ["uploaded_file", "manual_input"]:
                        st.session_state.pop(k, None)
                    st.rerun()
        with col_close:
            if st.button("‚ùå", help="–û—Ç–º–µ–Ω–∞"):
                st.session_state.pending_mode = None
                st.session_state.pending_confirm = False
                st.session_state.mode_ui_v += 1

    mode_text = st.session_state.mode

    # ===================== –†—É—á–Ω–æ–π –≤–≤–æ–¥ =====================
    def _set_manual_value(key: str, val: str):
        st.session_state[key] = val

    if mode_text == "–†—É—á–Ω–æ–π –≤–≤–æ–¥":
        st.header("–†—É—á–Ω–æ–π –≤–≤–æ–¥ –ø–∞—Ä —Ñ—Ä–∞–∑")
        with st.expander("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–¥–Ω—É –ø–∞—Ä—É —Ñ—Ä–∞–∑ (–±—ã—Å—Ç—Ä–æ)"):
            if "manual_text1" not in st.session_state:
                st.session_state["manual_text1"] = ""
            if "manual_text2" not in st.session_state:
                st.session_state["manual_text2"] = ""
            text1 = st.text_input("–§—Ä–∞–∑–∞ 1", key="manual_text1")
            text2 = st.text_input("–§—Ä–∞–∑–∞ 2", key="manual_text2")

            if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä—É", key="manual_check"):
                if not text1 or not text2:
                    st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–±–µ —Ñ—Ä–∞–∑—ã.")
                else:
                    t1 = preprocess_text(text1); t2 = preprocess_text(text2)
                    add_suggestions([t1, t2])
                    emb1 = encode_texts_in_batches(model_a, [t1], batch_size)
                    emb2 = encode_texts_in_batches(model_a, [t2], batch_size)
                    score_a = float(util.cos_sim(emb1[0], emb2[0]).item())
                    lex = jaccard_tokens(t1, t2)

                    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç (–º–æ–¥–µ–ª—å A)")
                    col1, col2, col3 = st.columns([1,1,1])
                    col1.metric("Score A", f"{score_a:.4f}")
                    col2.metric("Jaccard (lexical)", f"{lex:.4f}")

                    is_suspicious_single = False
                    if enable_detector and (score_a >= semantic_threshold) and (lex <= lexical_threshold):
                        is_suspicious_single = True
                        st.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ù–ï–û–ß–ï–í–ò–î–ù–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: –≤—ã—Å–æ–∫–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å, –Ω–∏–∑–∫–∞—è –ª–µ–∫—Å–∏—á–µ—Å–∫–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å.")

                    if model_b is not None:
                        emb1b = encode_texts_in_batches(model_b, [t1], batch_size)
                        emb2b = encode_texts_in_batches(model_b, [t2], batch_size)
                        score_b = float(util.cos_sim(emb1b[0], emb2b[0]).item())
                        delta = score_b - score_a
                        col3.metric("Score B", f"{score_b:.4f}", delta=f"{delta:+.4f}")
                        comp_df = pd.DataFrame({"model": ["A","B"], "score":[score_a, score_b]})
                        chart = alt.Chart(comp_df).mark_bar().encode(
                            x=alt.X('model:N', title=None),
                            y=alt.Y('score:Q', scale=alt.Scale(domain=[0,1]), title="Cosine similarity score"),
                            tooltip=['model','score']
                        )
                        st.altair_chart(chart.properties(width=300), use_container_width=False)
                    else:
                        col3.write("")

                    if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é", key="save_manual_single"):
                        rec = {
                            "source": "manual_single",
                            "pair": {"phrase_1": t1, "phrase_2": t2},
                            "score": score_a,
                            "score_b": float(score_b) if (model_b is not None) else None,
                            "lexical_score": lex,
                            "is_suspicious": is_suspicious_single,
                            "model_a": model_id,
                            "model_b": ab_model_id if enable_ab_test else None,
                            "timestamp": pd.Timestamp.now().isoformat()
                        }
                        add_to_history(rec)
                        st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏–∏.")

        with st.expander("–í–≤–µ—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä (–∫–∞–∂–¥–∞—è –ø–∞—Ä–∞ –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ). –§–æ—Ä–º–∞—Ç: `—Ñ—Ä–∞–∑–∞1 || —Ñ—Ä–∞–∑–∞2` / TAB / `,`"):
            bulk_text = st.text_area("–í—Å—Ç–∞–≤—å—Ç–µ –ø–∞—Ä—ã (–ø–æ –æ–¥–Ω–æ–π –≤ —Å—Ç—Ä–æ–∫–µ)", height=180, key="bulk_pairs")
            st.caption("–ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `||`.")
            if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ –ø–∞—Ä—ã (—Ä—É—á–Ω–æ–π –≤–≤–æ–¥)", key="manual_bulk_check"):
                lines = [l.strip() for l in bulk_text.splitlines() if l.strip()]
                if not lines:
                    st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –≤–≤–µ–¥–µ–Ω–æ.")
                else:
                    parsed = []
                    for ln in lines:
                        if "||" in ln:
                            p1, p2 = ln.split("||", 1)
                        elif "\t" in ln:
                            p1, p2 = ln.split("\t", 1)
                        elif "," in ln:
                            p1, p2 = ln.split(",", 1)
                        else:
                            p1, p2 = ln, ""
                        parsed.append((preprocess_text(p1), preprocess_text(p2)))
                    parsed = [(a,b) for a,b in parsed if a and b]
                    if not parsed:
                        st.warning("–ù–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –ø–∞—Ä.")
                    else:
                        add_suggestions([p for pair in parsed for p in pair])
                        phrases_all = list({p for pair in parsed for p in pair})
                        phrase2idx = {p:i for i,p in enumerate(phrases_all)}
                        with st.spinner("–ö–æ–¥–∏—Ä—É—é —Ñ—Ä–∞–∑—ã –º–æ–¥–µ–ª—å—é A..."):
                            embeddings_a = encode_texts_in_batches(model_a, phrases_all, batch_size)
                        embeddings_b = None
                        if model_b is not None:
                            with st.spinner("–ö–æ–¥–∏—Ä—É—é —Ñ—Ä–∞–∑—ã –º–æ–¥–µ–ª—å—é B..."):
                                embeddings_b = encode_texts_in_batches(model_b, phrases_all, batch_size)
                        rows = []
                        for p1, p2 in parsed:
                            emb1 = embeddings_a[phrase2idx[p1]]
                            emb2 = embeddings_a[phrase2idx[p2]]
                            score_a = float(util.cos_sim(emb1, emb2).item())
                            score_b = None
                            if embeddings_b is not None:
                                emb1b = embeddings_b[phrase2idx[p1]]
                                emb2b = embeddings_b[phrase2idx[p2]]
                                score_b = float(util.cos_sim(emb1b, emb2b).item())
                            lex = jaccard_tokens(p1, p2)
                            rows.append({"phrase_1": p1, "phrase_2": p2, "score": score_a, "score_b": score_b, "lexical_score": lex})
                        res_df = pd.DataFrame(rows)
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ä—É—á–Ω–æ–π –º–∞—Å—Å–æ–≤—ã–π –≤–≤–æ–¥)")
                        styled = style_suspicious_and_low(res_df, semantic_threshold, lexical_threshold, low_score_threshold)
                        st.dataframe(styled, use_container_width=True)
                        csv_bytes = res_df.to_csv(index=False).encode('utf-8')
                        st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã CSV", data=csv_bytes, file_name="manual_results.csv", mime="text/csv")

                        if enable_detector:
                            susp_df = res_df[(res_df["score"] >= semantic_threshold) & (res_df["lexical_score"] <= lexical_threshold)]
                            if not susp_df.empty:
                                st.markdown("### –ù–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (high semantic, low lexical)")
                                st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(susp_df)} –ø–∞—Ä.")
                                st.dataframe(susp_df, use_container_width=True)
                                susp_csv = susp_df.to_csv(index=False).encode('utf-8')
                                st.download_button("–°–∫–∞—á–∞—Ç—å suspicious CSV", data=susp_csv, file_name="suspicious_manual_bulk.csv", mime="text/csv")
                                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å suspicious –≤ –∏—Å—Ç–æ—Ä–∏—é", key="save_susp_manual"):
                                    rec = {
                                        "source": "manual_bulk_suspicious",
                                        "pairs_count": len(susp_df),
                                        "results": susp_df.to_dict(orient="records"),
                                        "model_a": model_id,
                                        "model_b": ab_model_id if enable_ab_test else None,
                                        "timestamp": pd.Timestamp.now().isoformat(),
                                        "semantic_threshold": semantic_threshold,
                                        "lexical_threshold": lexical_threshold
                                    }
                                    add_to_history(rec)
                                    st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏–∏.")

    # ===================== –ë–ª–æ–∫: —Ñ–∞–π–ª =====================
    if mode_text == "–§–∞–π–ª (CSV/XLSX/JSON)":
        st.header("1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: phrase_1, phrase_2, topics (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª", type=["csv", "xlsx", "xls", "json", "ndjson"])

        if uploaded_file is not None:
            try:
                from utils import read_uploaded_file_bytes  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –Ω–µ —É—Ç—è–∂–µ–ª—è—Ç—å –≤–µ—Ä—Ö
                df, file_hash = read_uploaded_file_bytes(uploaded_file)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
                st.stop()

            required_cols = {"phrase_1", "phrase_2"}
            if not required_cols.issubset(set(df.columns)):
                st.error(f"–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: {required_cols}")
                st.stop()

            # --- –†–µ–¥–∞–∫—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
            st.subheader("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π")
            st.caption("–ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω—è—Ç—å, –¥–æ–±–∞–≤–ª—è—Ç—å –∏ —É–¥–∞–ª—è—Ç—å —Å—Ç—Ä–æ–∫–∏. –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏).")
            edited_df = st.data_editor(df, num_rows="dynamic", use_container_width=True, key="dataset_editor")
            edited_csv = edited_df.to_csv(index=False).encode('utf-8')
            st.download_button("üíæ –°–∫–∞—á–∞—Ç—å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (CSV)", data=edited_csv, file_name="edited_dataset.csv", mime="text/csv")
            df = edited_df.copy()

            # --- –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
            df["phrase_1"] = df["phrase_1"].map(preprocess_text)
            df["phrase_2"] = df["phrase_2"].map(preprocess_text)
            if "topics" in df.columns:
                df["topics_list"] = df["topics"].map(parse_topics_field)
            else:
                df["topics_list"] = [[] for _ in range(len(df))]

            # –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∫–∞–∂–¥–æ–π —Ñ—Ä–∞–∑–µ (–ø—Ä–æ—Å—Ç—ã–µ —Ñ–ª–∞–≥–∏)
            for col in ["phrase_1", "phrase_2"]:
                flags = df[col].map(simple_flags)
                df[f"{col}_len_tok"] = flags.map(lambda d: d["len_tok"])
                df[f"{col}_len_char"] = flags.map(lambda d: d["len_char"])
                df[f"{col}_has_neg"] = flags.map(lambda d: d["has_neg"])
                df[f"{col}_has_num"] = flags.map(lambda d: d["has_num"])
                df[f"{col}_has_date"] = flags.map(lambda d: d["has_date"])
                if _MORPH is not None:
                    df[f"{col}_pos1"] = df[col].map(pos_first_token)
                else:
                    df[f"{col}_pos1"] = "NA"

            add_suggestions(list(set(df["phrase_1"].tolist() + df["phrase_2"].tolist())))

            # --- –≠–Ω–∫–æ–¥–∏–Ω–≥
            phrases_all = list(set(df["phrase_1"].tolist() + df["phrase_2"].tolist()))
            phrase2idx = {p: i for i, p in enumerate(phrases_all)}
            with st.spinner("–ö–æ–¥–∏—Ä—É—é —Ñ—Ä–∞–∑—ã –º–æ–¥–µ–ª—å—é A..."):
                embeddings_a = encode_texts_in_batches(model_a, phrases_all, batch_size)
            embeddings_b = None
            if enable_ab_test and model_b is not None:
                with st.spinner("–ö–æ–¥–∏—Ä—É—é —Ñ—Ä–∞–∑—ã –º–æ–¥–µ–ª—å—é B..."):
                    embeddings_b = encode_texts_in_batches(model_b, phrases_all, batch_size)

            # --- –°—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –Ω–∞ –ø–∞—Ä–∞—Ö
            scores, scores_b, lexical_scores = [], [], []
            for _, row in df.iterrows():
                p1, p2 = row["phrase_1"], row["phrase_2"]
                emb1_a, emb2_a = embeddings_a[phrase2idx[p1]], embeddings_a[phrase2idx[p2]]
                score_a = float(util.cos_sim(emb1_a, emb2_a).item())
                scores.append(score_a)
                if embeddings_b is not None:
                    emb1_b, emb2_b = embeddings_b[phrase2idx[p1]], embeddings_b[phrase2idx[p2]]
                    scores_b.append(float(util.cos_sim(emb1_b, emb2_b).item()))
                lex_score = jaccard_tokens(p1, p2)
                lexical_scores.append(lex_score)

            df["score"] = scores
            if embeddings_b is not None:
                df["score_b"] = scores_b
            df["lexical_score"] = lexical_scores

            # --- –ü–∞–Ω–µ–ª–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (–≤–∫–ª–∞–¥–∫–∏)
            st.subheader("2. –ê–Ω–∞–ª–∏—Ç–∏–∫–∞")
            tabs = st.tabs(["–°–≤–æ–¥–∫–∞", "–†–∞–∑–≤–µ–¥–∫–∞ (Explore)", "–°—Ä–µ–∑—ã (Slices)", "A/B —Ç–µ—Å—Ç", "–≠–∫—Å–ø–æ—Ä—Ç"])

            # = Svodka =
            with tabs[0]:
                total = len(df)
                low_cnt = int((df["score"] < low_score_threshold).sum())
                susp_cnt = int(((df["score"] >= semantic_threshold) & (df["lexical_score"] <= lexical_threshold)).sum())
                colA, colB, colC, colD = st.columns(4)
                colA.metric("–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞", f"{total}")
                colB.metric("–°—Ä–µ–¥–Ω–∏–π score", f"{df['score'].mean():.4f}")
                colC.metric("–ú–µ–¥–∏–∞–Ω–∞ score", f"{df['score'].median():.4f}")
                colD.metric(f"–ù–∏–∑–∫–∏–µ (<{low_score_threshold:.2f})", f"{low_cnt} ({(low_cnt / max(total,1)):.0%})")
                st.caption(f"–ù–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (high-sem/low-lex): {susp_cnt} ({(susp_cnt / max(total,1)):.0%})")

            # = Explore =
            with tabs[1]:
                st.markdown("#### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏")
                left, right = st.columns(2)
                with left:
                    chart = alt.Chart(pd.DataFrame({"score": df["score"]})).mark_bar().encode(
                        alt.X("score:Q", bin=alt.Bin(maxbins=30), title="Cosine similarity score"),
                        y='count()', tooltip=['count()']
                    ).interactive()
                    st.altair_chart(chart, use_container_width=True)
                with right:
                    chart_lex = alt.Chart(pd.DataFrame({"lexical_score": df["lexical_score"]})).mark_bar().encode(
                        alt.X("lexical_score:Q", bin=alt.Bin(maxbins=30), title="Jaccard (–ª–µ–∫—Å–∏–∫–∞)"),
                        y='count()', tooltip=['count()']
                    ).interactive()
                    st.altair_chart(chart_lex, use_container_width=True)

                st.markdown("##### –¢–æ—á–µ—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫: —Å–µ–º–∞–Ω—Ç–∏–∫–∞ vs –ª–µ–∫—Å–∏–∫–∞")
                scatter_df = df[["score","lexical_score"]].copy()
                sc = alt.Chart(scatter_df).mark_point(opacity=0.6).encode(
                    x=alt.X("lexical_score:Q", title="Jaccard (–ª–µ–∫—Å–∏–∫–∞)"),
                    y=alt.Y("score:Q", title="Cosine similarity (—Å–µ–º–∞–Ω—Ç–∏–∫–∞)", scale=alt.Scale(domain=[0,1])),
                    tooltip=["score","lexical_score"]
                ).interactive()
                st.altair_chart(sc, use_container_width=True)

                if enable_detector:
                    st.markdown("##### –ù–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è")
                    susp_df = df[(df["score"] >= semantic_threshold) & (df["lexical_score"] <= lexical_threshold)]
                    if susp_df.empty:
                        st.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ –ø–æ—Ä–æ–≥–∏.")
                    else:
                        st.write(f"–ü–∞—Ä: {len(susp_df)}")
                        st.dataframe(susp_df[["phrase_1","phrase_2","score","lexical_score"]], use_container_width=True)

            # = Slices =
            with tabs[2]:
                st.markdown("#### –°—Ä–µ–∑—ã –∫–∞—á–µ—Å—Ç–≤–∞")
                # –ø—Ä–æ—Å—Ç—ã–µ —Ñ–ª–∞–≥–∏
                df["_any_neg"] = df["phrase_1_has_neg"] | df["phrase_2_has_neg"]
                df["_any_num"] = df["phrase_1_has_num"] | df["phrase_2_has_num"]
                df["_any_date"] = df["phrase_1_has_date"] | df["phrase_2_has_date"]
                # –¥–ª–∏–Ω–∞ (–ø–æ —Å—É–º–º–µ —Ç–æ–∫–µ–Ω–æ–≤ –æ–±–µ–∏—Ö —Ñ—Ä–∞–∑)
                def _len_bucket(r):
                    n = int(r["phrase_1_len_tok"] + r["phrase_2_len_tok"])
                    if n <= 4: return "[0,4]"
                    if n <= 9: return "[5,9]"
                    if n <= 19: return "[10,19]"
                    return "[20,+)"
                df["_len_bucket"] = df.apply(_len_bucket, axis=1)

                cols1 = st.columns(3)
                with cols1[0]:
                    st.markdown("**–ü–æ –¥–ª–∏–Ω–µ**")
                    agg_len = df.groupby("_len_bucket")["score"].agg(["count","mean","median"]).reset_index().sort_values("_len_bucket")
                    st.dataframe(agg_len, use_container_width=True)
                with cols1[1]:
                    st.markdown("**–û—Ç—Ä–∏—Ü–∞–Ω–∏—è/–ß–∏—Å–ª–∞/–î–∞—Ç—ã**")
                    flags_view = []
                    for flag in ["_any_neg","_any_num","_any_date"]:
                        sub = df[df[flag]]
                        flags_view.append({"—Ñ–ª–∞–≥":flag, "count":len(sub), "mean":float(sub["score"].mean()) if len(sub)>0 else np.nan})
                    st.dataframe(pd.DataFrame(flags_view), use_container_width=True)
                with cols1[2]:
                    if _MORPH is None:
                        st.info("–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è (POS) –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω pymorphy2")
                    else:
                        st.markdown("**POS –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞**")
                        pos_agg = df.groupby("phrase_1_pos1")["score"].agg(["count","mean"]).reset_index().rename(columns={"phrase_1_pos1":"POS"})
                        st.dataframe(pos_agg.sort_values("count", ascending=False), use_container_width=True)

                topic_mode = st.checkbox("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ topics", value=("topics_list" in df.columns))
                if topic_mode:
                    st.markdown("**–ü–æ —Ç–µ–º–∞–º (topics)**")
                    exploded = df.explode("topics_list")
                    exploded["topics_list"] = exploded["topics_list"].fillna("")
                    exploded = exploded[exploded["topics_list"].astype(str)!=""]
                    if exploded.empty:
                        st.info("–í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –Ω–µ–ø—É—Å—Ç—ã—Ö topics.")
                    else:
                        top_agg = exploded.groupby("topics_list")["score"].agg(["count","mean","median"]).reset_index().sort_values("count", ascending=False)
                        st.dataframe(top_agg, use_container_width=True)

            # = AB test =
            with tabs[3]:
                if (not enable_ab_test) or ("score_b" not in df.columns):
                    st.info("A/B —Ç–µ—Å—Ç –æ—Ç–∫–ª—é—á—ë–Ω –∏–ª–∏ –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ score_b.")
                else:
                    st.markdown("#### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π A vs B")
                    colx, coly, colz = st.columns(3)
                    colx.metric("–°—Ä–µ–¥–Ω–∏–π A", f"{df['score'].mean():.4f}")
                    coly.metric("–°—Ä–µ–¥–Ω–∏–π B", f"{df['score_b'].mean():.4f}")
                    colz.metric("Œî (B - A)", f"{(df['score_b'].mean()-df['score'].mean()):+.4f}")

                    n_boot = st.slider("–ë—É—Ç—Å—Ç—Ä—ç–ø –∏—Ç–µ—Ä–∞—Ü–∏–π", 200, 2000, 500, 100)
                    mean_diff, low, high = bootstrap_diff_ci(df["score_b"].to_numpy(), df["score"].to_numpy(), n_boot=n_boot)
                    st.write(f"–î–ò (95%) –¥–ª—è Œî (B‚àíA): **[{low:+.4f}, {high:+.4f}]**, —Å—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: **{mean_diff:+.4f}**")
                    ab_df = pd.DataFrame({"A": df["score"], "B": df["score_b"]})
                    ab_chart = alt.Chart(ab_df.reset_index()).mark_point(opacity=0.5).encode(
                        x=alt.X("A:Q", scale=alt.Scale(domain=[0,1])),
                        y=alt.Y("B:Q", scale=alt.Scale(domain=[0,1])),
                        tooltip=["A","B"]
                    ).interactive()
                    st.altair_chart(ab_chart, use_container_width=True)

                    delta_df = df.copy()
                    delta_df["delta"] = delta_df["score_b"] - delta_df["score"]
                    st.markdown("**–¢–æ–ø, –≥–¥–µ B ‚â´ A**")
                    st.dataframe(
                        delta_df.sort_values("delta", ascending=False).head(10)[["phrase_1","phrase_2","score","score_b","delta"]],
                        use_container_width=True
                    )
                    st.markdown("**–¢–æ–ø, –≥–¥–µ A ‚â´ B**")
                    st.dataframe(
                        delta_df.sort_values("delta", ascending=True).head(10)[["phrase_1","phrase_2","score","score_b","delta"]],
                        use_container_width=True
                    )

            # = Export =
            with tabs[4]:
                st.markdown("#### –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á—ë—Ç–∞ (JSON)")
                report = {
                    "file_name": uploaded_file.name,
                    "file_hash": file_hash,
                    "n_pairs": int(len(df)),
                    "model_a": model_id,
                    "model_b": ab_model_id if enable_ab_test else None,
                    "thresholds": {
                        "semantic_threshold": float(semantic_threshold),
                        "lexical_threshold": float(lexical_threshold),
                        "low_score_threshold": float(low_score_threshold)
                    },
                    "summary": {
                        "mean_score": float(df["score"].mean()),
                        "median_score": float(df["score"].median()),
                        "low_count": int((df["score"] < low_score_threshold).sum()),
                        "suspicious_count": int(((df["score"] >= semantic_threshold) & (df["lexical_score"] <= lexical_threshold)).sum())
                    }
                }
                rep_bytes = json.dumps(report, ensure_ascii=False, indent=2).encode("utf-8")
                st.download_button("üíæ –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç JSON", data=rep_bytes, file_name="synonym_checker_report.json", mime="application/json")

            # --- –í—ã–≥—Ä—É–∑–∫–∞ + –ø–æ–¥—Å–≤–µ—Ç–∫–∞
            st.subheader("3. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≥—Ä—É–∑–∫–∞")
            result_csv = df.to_csv(index=False).encode('utf-8')
            st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã CSV", data=result_csv, file_name="results.csv", mime="text/csv")
            styled_df = style_suspicious_and_low(df, semantic_threshold, lexical_threshold, low_score_threshold)
            st.dataframe(styled_df, use_container_width=True)

            # --- Suspicious –±–ª–æ–∫ –∏ –∏—Å—Ç–æ—Ä–∏—è
            if enable_detector:
                susp_df = df[(df["score"] >= semantic_threshold) & (df["lexical_score"] <= lexical_threshold)]
                st.markdown("### –ù–µ–æ—á–µ–≤–∏–¥–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (high semantic, low lexical)")
                if susp_df.empty:
                    st.write("–ù–µ –Ω–∞–π–¥–µ–Ω–æ.")
                else:
                    st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(susp_df)} –ø–∞—Ä.")
                    st.dataframe(susp_df, use_container_width=True)
                    susp_csv = susp_df.to_csv(index=False).encode('utf-8')
                    st.download_button("–°–∫–∞—á–∞—Ç—å suspicious CSV", data=susp_csv, file_name="suspicious_file_mode.csv", mime="text/csv")
                    if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å suspicious –≤ –∏—Å—Ç–æ—Ä–∏—é", key="save_susp_file"):
                        rec = {
                            "source": "file_suspicious",
                            "file_hash": file_hash,
                            "file_name": uploaded_file.name,
                            "pairs_count": len(susp_df),
                            "results": susp_df.to_dict(orient="records"),
                            "model_a": model_id,
                            "model_b": ab_model_id if enable_ab_test else None,
                            "timestamp": pd.Timestamp.now().isoformat(),
                            "semantic_threshold": semantic_threshold,
                            "lexical_threshold": lexical_threshold
                        }
                        add_to_history(rec)
                        st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏–∏.")
        else:
            st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏.")

    # ===================== –ò—Å—Ç–æ—Ä–∏—è –≤–Ω–∏–∑—É =====================
    if st.session_state["history"]:
        st.header("–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫")
        for idx, rec in enumerate(reversed(st.session_state["history"])):
            st.markdown(f"### –ü—Ä–æ–≤–µ—Ä–∫–∞ #{len(st.session_state['history']) - idx}")
            if rec.get("source") == "manual_single":
                p = rec.get("pair", {})
                st.markdown(f"**–†—É—á–Ω–æ–π –≤–≤–æ–¥ (single)**  |  **–î–∞—Ç–∞:** {rec.get('timestamp','-')}")
                st.markdown(f"**–§—Ä–∞–∑—ã:** `{p.get('phrase_1','')}`  ‚Äî `{p.get('phrase_2','')}`")
                st.markdown(f"**Score A:** {rec.get('score', '-')}, **Score B:** {rec.get('score_b', '-')}, **Lexical:** {rec.get('lexical_score','-')}")
                if rec.get("is_suspicious"):
                    st.warning("–≠—Ç–∞ –ø–∞—Ä–∞ –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ –Ω–µ–æ—á–µ–≤–∏–¥–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (high semantic, low lexical).")
            elif rec.get("source") == "manual_bulk":
                st.markdown(f"**–†—É—á–Ω–æ–π –≤–≤–æ–¥ (bulk)**  |  **–î–∞—Ç–∞:** {rec.get('timestamp','-')}")
                st.markdown(f"**–ü–∞—Ä:** {rec.get("pairs_count", 0)}  |  **–ú–æ–¥–µ–ª—å A:** {rec.get('model_a','-')}")
                saved_df = pd.DataFrame(rec.get("results", []))
                if not saved_df.empty:
                    styled_hist_df = style_suspicious_and_low(saved_df, rec.get("semantic_threshold", 0.8), rec.get("lexical_threshold", 0.3), 0.75)
                    st.dataframe(styled_hist_df, use_container_width=True)
            elif rec.get("source") in ("manual_bulk_suspicious",):
                st.markdown(f"**–†—É—á–Ω–æ–π suspicious**  |  **–î–∞—Ç–∞:** {rec.get('timestamp','-')}")
                st.markdown(f"**–ü–∞—Ä:** {rec.get("pairs_count", 0)}  |  **–ú–æ–¥–µ–ª—å A:** {rec.get('model_a','-')}")
                saved_df = pd.DataFrame(rec.get("results", []))
                if not saved_df.empty:
                    st.dataframe(saved_df, use_container_width=True)
            elif rec.get("source") == "file_suspicious":
                st.markdown(f"**–§–∞–π–ª (suspicious)**  |  **–§–∞–π–ª:** {rec.get('file_name','-')}  |  **–î–∞—Ç–∞:** {rec.get('timestamp','-')}")
                st.markdown(f"**–ü–∞—Ä:** {rec.get("pairs_count", 0)}  |  **–ú–æ–¥–µ–ª—å A:** {rec.get('model_a','-')}")
                saved_df = pd.DataFrame(rec.get("results", []))
                if not saved_df.empty:
                    st.dataframe(saved_df, use_container_width=True)
            else:
                st.markdown(f"**–§–∞–π–ª:** {rec.get('file_name','-')}  |  **–î–∞—Ç–∞:** {rec.get('timestamp','-')}")
                st.markdown(f"**–ú–æ–¥–µ–ª—å A:** {rec.get('model_a','-')}  |  **–ú–æ–¥–µ–ª—å B:** {rec.get('model_b','-')}")
                saved_df = pd.DataFrame(rec.get("results", []))
                if not saved_df.empty:
                    styled_hist_df = style_suspicious_and_low(saved_df, 0.8, 0.3, 0.75)
                    st.dataframe(styled_hist_df, use_container_width=True)
            st.markdown("---")

# ===================== –†–ï–ñ–ò–ú: –ú–£–õ–¨–¢–ò–ú–û–î–ê–õ–¨–ù–´–ï –ú–û–î–ï–õ–ò =====================
elif mode == "–†–∞–±–æ—Ç–∞ —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏":
    # ===================== –†–ï–ñ–ò–ú: –ú–£–õ–¨–¢–ò–ú–û–î–ê–õ–¨–ù–´–ï –ú–û–î–ï–õ–ò =====================
    import io, json, zipfile
    from typing import List, Optional, Dict
    import numpy as np
    import pandas as pd
    import streamlit as st
    from PIL import Image

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–≤–æ–π –º–æ–¥—É–ª—å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π (–±–µ–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º)
    from multimodal import load_blip_model, load_clip_model, generate_caption

    # –í–Ω–µ—à–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ graceful)
    try:
        import torch
    except Exception:
        torch = None
    try:
        import altair as alt
    except Exception:
        alt = None
    try:
        import matplotlib.pyplot as plt
    except Exception:
        plt = None
    try:
        from openai import OpenAI  # OpenAI SDK >=1.0
    except Exception:
        OpenAI = None

    st.header("üñºÔ∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")

    # ===================== –ò—Å—Ç–æ—Ä–∏—è =====================
    if "mm_history" not in st.session_state:
        st.session_state["mm_history"] = []

    def mm_add_history(record: Dict):
        st.session_state["mm_history"].append(record)
        if len(st.session_state["mm_history"]) > 300:
            st.session_state["mm_history"] = st.session_state["mm_history"][-300:]

    # ===================== –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ =====================
    st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")

    # –ò—Å—Ç–æ—á–Ω–∏–∫ –∏ ID –º–æ–¥–µ–ª–µ–π (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —É —Ç–µ–±—è)
    clip_source_a = st.sidebar.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ CLIP (A)", ["huggingface", "google_drive"], index=0, key="mm_clip_source_a")
    clip_id_a = st.sidebar.text_input("CLIP (A) Model ID", value="openai/clip-vit-base-patch32", key="mm_clip_id_a")

    enable_ab = st.sidebar.checkbox("A/B: –í–∫–ª—é—á–∏—Ç—å CLIP (B)", value=False, key="mm_enable_ab")
    if enable_ab:
        clip_source_b = st.sidebar.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ CLIP (B)", ["huggingface", "google_drive"], index=0, key="mm_clip_source_b")
        clip_id_b = st.sidebar.text_input("CLIP (B) Model ID", value="laion/CLIP-ViT-B-32-laion2B-s34B-b79K", key="mm_clip_id_b")
    else:
        clip_source_b, clip_id_b = None, None

    blip_source = st.sidebar.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ BLIP", ["huggingface", "google_drive"], index=0, key="mm_blip_source")
    blip_caption_id = st.sidebar.text_input("BLIP Caption Model ID", value="Salesforce/blip-image-captioning-base", key="mm_blip_caption_id")
    blip_vqa_id = st.sidebar.text_input("BLIP VQA Model ID", value="Salesforce/blip-vqa-base", key="mm_blip_vqa_id")

    # LLM-–æ—Ü–µ–Ω–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    use_llm_eval = st.sidebar.checkbox("LLM-–æ—Ü–µ–Ω–∫–∞ (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API)", value=False, key="mm_use_llm")
    if use_llm_eval:
        llm_api_key = st.sidebar.text_input("API Key", type="password", key="mm_llm_key")
        llm_api_base = st.sidebar.text_input("API Base (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", key="mm_llm_base")
        llm_model_name = st.sidebar.text_input("–ú–æ–¥–µ–ª—å (LLM)", value="gpt-4o-mini", key="mm_llm_model")
    else:
        llm_api_key = llm_api_base = llm_model_name = None

    # ===================== –ö–µ—à-–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π =====================
    @st.cache_resource(show_spinner=False)
    def mm_load_clip(source: str, model_id: str):
        try:
            model, proc = load_clip_model(source, model_id)
            return model, proc
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CLIP {model_id}: {e}")
            return None, None

    @st.cache_resource(show_spinner=False)
    def mm_load_blip(source: str, model_id: str):
        try:
            model, proc = load_blip_model(source, model_id)
            return model, proc
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å BLIP {model_id}: {e}")
            return None, None

    clip_model_a, clip_proc_a = mm_load_clip(clip_source_a, clip_id_a)
    clip_model_b, clip_proc_b = (mm_load_clip(clip_source_b, clip_id_b) if (enable_ab and clip_id_b) else (None, None))
    blip_cap_model, blip_cap_proc = mm_load_blip(blip_source, blip_caption_id)
    blip_vqa_model, blip_vqa_proc = mm_load_blip(blip_source, blip_vqa_id)

    # ===================== –ú–µ—Ç—Ä–∏–∫–∏ –∏ —É—Ç–∏–ª–∏—Ç—ã (–ø—Ä–µ—Ñ–∏–∫—Å mm_ –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏) =====================
    def mm_ngrams(tokens: List[str], n: int):
        return set(tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1))

    def mm_bleu_n(ref: str, hyp: str, n: int = 4) -> float:
        ref_t, hyp_t = ref.lower().split(), hyp.lower().split()
        if not hyp_t:
            return 0.0
        score = 0.0
        for k in range(1, n+1):
            ref_ngr, hyp_ngr = mm_ngrams(ref_t, k), mm_ngrams(hyp_t, k)
            denom = max(len(hyp_ngr), 1)
            score += len(ref_ngr & hyp_ngr) / denom
        return score / n

    def mm_rouge_l(ref: str, hyp: str) -> float:
        ref_t, hyp_t = ref.lower().split(), hyp.lower().split()
        dp = [[0]*(len(hyp_t)+1) for _ in range(len(ref_t)+1)]
        for i in range(1, len(ref_t)+1):
            for j in range(1, len(hyp_t)+1):
                if ref_t[i-1] == hyp_t[j-1]:
                    dp[i][j] = dp[i-1][j-1] + 1
                else:
                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])
        return dp[-1][-1] / max(len(ref_t), 1)

    def mm_distinct_n(hyps: List[str], n: int = 2) -> float:
        ngrams = []
        for h in hyps:
            t = h.lower().split()
            ngrams.extend([tuple(t[i:i+n]) for i in range(len(t)-n+1)])
        return len(set(ngrams)) / max(len(ngrams), 1)

    def mm_self_bleu(hyps: List[str], n: int = 4) -> float:
        scores = []
        for i, h in enumerate(hyps):
            others = hyps[:i] + hyps[i+1:]
            if not others:
                continue
            ref = " ".join(others)
            scores.append(mm_bleu_n(ref, h, n=n))
        return float(np.mean(scores)) if scores else 0.0

    def mm_light_cider(refs: List[str], hyps: List[str], n_max: int = 4) -> float:
        scores = []
        for r, h in zip(refs, hyps):
            r_t, h_t = r.lower().split(), h.lower().split()
            if not h_t:
                scores.append(0.0); continue
            s = 0.0
            for n in range(1, n_max+1):
                r_ngr, h_ngr = mm_ngrams(r_t, n), mm_ngrams(h_t, n)
                s += len(r_ngr & h_ngr) / max(len(h_ngr), 1)
            scores.append(s/n_max)
        return float(np.mean(scores)) if scores else 0.0

    def mm_light_spice(refs: List[str], hyps: List[str]) -> float:
        scores = []
        for r, h in zip(refs, hyps):
            scores.append(len(set(r.lower().split()) & set(h.lower().split())) / max(len(h.split()), 1))
        return float(np.mean(scores)) if scores else 0.0

    def mm_normalize(mat: np.ndarray) -> np.ndarray:
        return mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)

    def mm_cosine_sim(a: np.ndarray, b: np.ndarray) -> np.ndarray:
        return mm_normalize(a) @ mm_normalize(b).T

    def mm_clipscore(clip_model, clip_proc, hyps: List[str], imgs: List[Image.Image]) -> float:
        if clip_model is None or clip_proc is None or not hyps or not imgs or torch is None:
            return 0.0
        with torch.no_grad():
            t = clip_model.get_text_features(**clip_proc(text=hyps, return_tensors="pt", padding=True, truncation=True)).cpu().numpy()
            i = clip_model.get_image_features(**clip_proc(images=imgs, return_tensors="pt")).cpu().numpy()
        sim = mm_cosine_sim(t, i)
        return float(np.mean(np.diag(sim)))

    def mm_recall_at_k(sim_matrix: np.ndarray, k: int) -> float:
        ranks = np.argsort(-sim_matrix, axis=1)
        hits = sum(1 if i in ranks[i, :k] else 0 for i in range(sim_matrix.shape[0]))
        return hits / sim_matrix.shape[0] if sim_matrix.size else 0.0

    def mm_mean_average_precision(sim_matrix: np.ndarray) -> float:
        if sim_matrix.size == 0:
            return 0.0
        y_true = np.eye(sim_matrix.shape[0])
        aps = []
        for i in range(sim_matrix.shape[0]):
            y = y_true[i]
            scores = sim_matrix[i]
            order = np.argsort(-scores)
            y_sorted = y[order]
            prec, hit = [], 0
            for j, rel in enumerate(y_sorted, start=1):
                if rel > 0:
                    hit += 1
                    prec.append(hit / j)
            aps.append(np.mean(prec) if prec else 0.0)
        return float(np.mean(aps))

    def mm_ndcg(sim_matrix: np.ndarray, k: int = 10) -> float:
        n = sim_matrix.shape[0]
        if n == 0:
            return 0.0
        ndcgs = []
        for i in range(n):
            scores = sim_matrix[i]
            idx = np.argsort(-scores)[:k]
            gains = [1 if j == i else 0 for j in idx]
            discounts = [1/np.log2(r+2) for r in range(len(gains))]
            dcg = sum(g * d for g, d in zip(gains, discounts))
            ndcgs.append(dcg/1.0)
        return float(np.mean(ndcgs)) if ndcgs else 0.0

    def mm_median_rank(sim_matrix: np.ndarray) -> float:
        if sim_matrix.size == 0:
            return 0.0
        ranks = np.argsort(-sim_matrix, axis=1)
        positions = [int(np.where(ranks[i] == i)[0][0]) + 1 for i in range(sim_matrix.shape[0])]
        return float(np.median(positions)) if positions else 0.0

    def mm_bootstrap_metric_diff(rows: int, metric_fn, sim_a: np.ndarray, sim_b: np.ndarray, iters: int = 300, k: Optional[int] = None, seed: int = 42):
        rng = np.random.default_rng(seed)
        diffs = []
        for _ in range(iters):
            idx = rng.integers(0, rows, size=rows)
            sa, sb = sim_a[idx][:, idx], sim_b[idx][:, idx]
            if metric_fn in (mm_recall_at_k, mm_ndcg):
                diffs.append(metric_fn(sb, k) - metric_fn(sa, k))
            else:
                diffs.append(metric_fn(sb) - metric_fn(sa))
        return np.array(diffs)

    # –ü—Ä–∏–±–ª–∏–∂—ë–Ω–Ω—ã–π CLIP-FID (–≤ CLIP-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ)
    def mm_frechet_distance(mu1, sigma1, mu2, sigma2):
        try:
            from scipy import linalg
            covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
            if np.iscomplexobj(covmean):
                covmean = covmean.real
            diff = mu1 - mu2
            return diff.dot(diff) + np.trace(sigma1 + sigma2 - 2*covmean)
        except Exception:
            diff = mu1 - mu2
            return diff.dot(diff) + np.sum(sigma1 + sigma2 - 2*np.sqrt(np.maximum(sigma1 * sigma2, 1e-12)))

    def mm_clip_fid(clip_model, clip_proc, real_imgs: List[Image.Image], gen_imgs: List[Image.Image]) -> float:
        if clip_model is None or clip_proc is None or torch is None or not real_imgs or not gen_imgs:
            return 0.0
        with torch.no_grad():
            real = clip_model.get_image_features(**clip_proc(images=real_imgs, return_tensors="pt")).cpu().numpy()
            gen = clip_model.get_image_features(**clip_proc(images=gen_imgs, return_tensors="pt")).cpu().numpy()
        mu_r, mu_g = real.mean(axis=0), gen.mean(axis=0)
        cov_r, cov_g = np.cov(real, rowvar=False), np.cov(gen, rowvar=False)
        return float(mm_frechet_distance(mu_r, cov_r, mu_g, cov_g))

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è BLIP (caption) –∏ –ø—Ä–æ—Å—Ç–æ–π VQA-–≤—ã–∑–æ–≤
    def mm_blip_generate_caption(model, proc, img: Image.Image, max_new_tokens: int = 30) -> str:
        try:
            return generate_caption(model, proc, img)
        except Exception:
            # –§–æ–ª–ª–±—ç–∫ —á–µ—Ä–µ–∑ .generate (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
            if model is None or proc is None or torch is None:
                return ""
            inputs = proc(images=img, text="A photo of", return_tensors="pt")
            with torch.no_grad():
                out = model.generate(**inputs, max_new_tokens=max_new_tokens)
            try:
                return proc.batch_decode(out, skip_special_tokens=True)[0]
            except Exception:
                return ""

    def mm_blip_vqa_answer(model, proc, img: Image.Image, question: str, max_new_tokens: int = 20) -> str:
        if model is None or proc is None or torch is None:
            return ""
        inputs = proc(images=img, text=question, return_tensors="pt")
        with torch.no_grad():
            out = model.generate(**inputs, max_new_tokens=max_new_tokens)
        try:
            return proc.batch_decode(out, skip_special_tokens=True)[0]
        except Exception:
            return ""

    # ===================== –í–∫–ª–∞–¥–∫–∏ =====================
    tab_cap, tab_ret, tab_gen, tab_vqa, tab_hist = st.tabs(
        ["üñºÔ∏è Caption Eval", "üîé Retrieval Eval", "üé® ImageGen Eval", "‚ùì VQA Eval", "üóÇÔ∏è –ò—Å—Ç–æ—Ä–∏—è"]
    )

    # ===================== 1) Caption Evaluation =====================
    with tab_cap:
        st.subheader("üñºÔ∏è –û—Ü–µ–Ω–∫–∞ Captioning")
        c1, c2, c3 = st.columns(3)
        with c1:
            csv_cap = st.file_uploader("CSV (image, reference_caption)", type=["csv"], key="mm_cap_csv")
        with c2:
            zip_cap = st.file_uploader("ZIP images", type=["zip"], key="mm_cap_zip")
        with c3:
            do_generate = st.checkbox("–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å BLIP –ø–æ–¥–ø–∏—Å–∏", value=True, key="mm_cap_gen")

        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å Caption Eval", type="primary", key="mm_cap_run"):
            if not (csv_cap and zip_cap):
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏ ZIP —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.")
            else:
                df = pd.read_csv(csv_cap)
                zbytes = io.BytesIO(zip_cap.read())
                with zipfile.ZipFile(zbytes) as zf:
                    refs, hyps, imgs = [], [], []
                    for _, row in df.iterrows():
                        fname = str(row.get("image", ""))
                        ref = str(row.get("reference_caption", ""))
                        if not fname or fname not in zf.namelist():
                            st.warning(f"–ù–µ—Ç —Ñ–∞–π–ª–∞ –≤ ZIP: {fname}")
                            continue
                        with zf.open(fname) as f:
                            img = Image.open(io.BytesIO(f.read())).convert("RGB")
                        hyp = mm_blip_generate_caption(blip_cap_model, blip_cap_proc, img) if do_generate else ref
                        refs.append(ref); hyps.append(hyp); imgs.append(img)

                if refs:
                    bleu = float(np.mean([mm_bleu_n(r, h) for r, h in zip(refs, hyps)]))
                    rouge = float(np.mean([mm_rouge_l(r, h) for r, h in zip(refs, hyps)]))
                    cider_val = mm_light_cider(refs, hyps)
                    spice_val = mm_light_spice(refs, hyps)
                    dist2 = mm_distinct_n(hyps, n=2)
                    sbleu = mm_self_bleu(hyps)
                    clip_score_val = mm_clipscore(clip_model_a, clip_proc_a, hyps, imgs)

                    m1, m2, m3, m4, m5, m6, m7 = st.columns(7)
                    m1.metric("BLEU", f"{bleu:.3f}")
                    m2.metric("ROUGE-L", f"{rouge:.3f}")
                    m3.metric("CIDEr (light)", f"{cider_val:.3f}")
                    m4.metric("SPICE (light)", f"{spice_val:.3f}")
                    m5.metric("Distinct-2", f"{dist2:.3f}")
                    m6.metric("Self-BLEU", f"{sbleu:.3f}")
                    m7.metric("CLIPScore", f"{clip_score_val:.3f}")

                    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è LLM-–æ—Ü–µ–Ω–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
                    llm_judgements = []
                    if use_llm_eval and llm_api_key and OpenAI is not None:
                        try:
                            client = OpenAI(api_key=llm_api_key, base_url=llm_api_base or None)
                            max_items = min(12, len(refs))
                            with st.expander("ü§ñ LLM-–æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ (–¥–æ 12)"):
                                for i in range(max_items):
                                    prompt = (
                                        "–û—Ü–µ–Ω–∏ –ø–æ–¥–ø–∏—Å—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –ø–æ–ª–Ω–æ—Ç–µ. "
                                        "–í–µ—Ä–Ω–∏ –ß–ò–°–õ–û 1‚Äì10 –∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
                                        f"–≠—Ç–∞–ª–æ–Ω: {refs[i]}\n–ö–∞–ø—à–µ–Ω: {hyps[i]}"
                                    )
                                    resp = client.chat.completions.create(
                                        model=llm_model_name or "gpt-4o-mini",
                                        messages=[{"role": "user", "content": prompt}],
                                        temperature=0
                                    )
                                    txt = resp.choices[0].message.content.strip()
                                    st.write(f"#{i+1} ‚Üí {txt}")
                                    llm_judgements.append({"ref": refs[i], "hyp": hyps[i], "judge": txt})
                        except Exception as e:
                            st.info(f"LLM-–æ—Ü–µ–Ω–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")

                    # –ë—ã—Å—Ç—Ä–∞—è —Ä—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                    with st.expander("üßë‚Äç‚öñÔ∏è –ë—ã—Å—Ç—Ä–∞—è —Ä—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞"):
                        ratings = []
                        grid_cols = st.columns(4)
                        for idx in range(min(12, len(imgs))):
                            with grid_cols[idx % 4]:
                                st.image(imgs[idx], use_column_width=True)
                                st.caption(f"Ref: {refs[idx]}\n\nHyp: {hyps[idx]}")
                                r = st.slider("–û—Ü–µ–Ω–∫–∞ (1‚Äì5)", 1, 5, 3, key=f"mm_cap_rate_{idx}")
                                ratings.append({"ref": refs[idx], "hyp": hyps[idx], "rating": int(r)})

                    mm_add_history({
                        "type": "caption_eval",
                        "metrics": {"bleu": bleu, "rouge_l": rouge, "cider_light": cider_val, "spice_light": spice_val,
                                    "distinct_2": dist2, "self_bleu": sbleu, "clipscore": clip_score_val},
                        "llm": llm_judgements[:],
                    })
                    st.success("–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –ò—Å—Ç–æ—Ä–∏—é.")

    # ===================== 2) Retrieval Evaluation =====================
    with tab_ret:
        st.subheader("üîé –û—Ü–µ–Ω–∫–∞ Retrieval (Text‚ÜíImage)")
        c1, c2, c3 = st.columns(3)
        with c1:
            csv_ret = st.file_uploader("CSV (text,image)", type=["csv"], key="mm_ret_csv")
        with c2:
            zip_ret = st.file_uploader("ZIP images", type=["zip"], key="mm_ret_zip")
        with c3:
            n_boot = st.slider("–ë—É—Ç—Å—Ç—Ä—ç–ø –∏—Ç–µ—Ä–∞—Ü–∏–π", 100, 800, 300, 50, key="mm_ret_boot")

        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å Retrieval", type="primary", key="mm_ret_run"):
            if not (csv_ret and zip_ret):
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏ ZIP —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.")
            else:
                df = pd.read_csv(csv_ret)
                zbytes = io.BytesIO(zip_ret.read())
                with zipfile.ZipFile(zbytes) as zf:
                    imgs, texts = [], []
                    for _, row in df.iterrows():
                        text = str(row.get("text", str(row.iloc[0])))
                        fname = str(row.get("image", str(row.iloc[1])))
                        if fname not in zf.namelist():
                            st.warning(f"–ù–µ—Ç —Ñ–∞–π–ª–∞ –≤ ZIP: {fname}")
                            continue
                        with zf.open(fname) as f:
                            imgs.append(Image.open(io.BytesIO(f.read())).convert("RGB"))
                        texts.append(text)

                if imgs:
                    if clip_model_a is None or clip_proc_a is None or torch is None:
                        st.error("CLIP (A) –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.")
                    else:
                        with torch.no_grad():
                            t_emb_a = clip_model_a.get_text_features(**clip_proc_a(text=texts, return_tensors="pt", padding=True, truncation=True)).cpu().numpy()
                            i_emb_a = clip_model_a.get_image_features(**clip_proc_a(images=imgs, return_tensors="pt")).cpu().numpy()
                        sim_a = mm_cosine_sim(t_emb_a, i_emb_a)

                        r1, r5, r10 = mm_recall_at_k(sim_a, 1), mm_recall_at_k(sim_a, 5), mm_recall_at_k(sim_a, 10)
                        map_score = mm_mean_average_precision(sim_a)
                        ndcg10 = mm_ndcg(sim_a, 10)
                        med_rank = mm_median_rank(sim_a)

                        m1, m2, m3, m4, m5, m6 = st.columns(6)
                        m1.metric("R@1", f"{r1:.3f}")
                        m2.metric("R@5", f"{r5:.3f}")
                        m3.metric("R@10", f"{r10:.3f}")
                        m4.metric("mAP", f"{map_score:.3f}")
                        m5.metric("nDCG@10", f"{ndcg10:.3f}")
                        m6.metric("Median Rank", f"{med_rank:.1f}")

                        # –ö—Ä–∏–≤–∞—è Recall@k
                        ks = list(range(1, min(21, sim_a.shape[1] + 1)))
                        curve = pd.DataFrame({"k": ks, "Recall@k": [mm_recall_at_k(sim_a, k) for k in ks]})
                        try:
                            st.line_chart(curve.set_index("k"))
                        except Exception:
                            st.dataframe(curve)

                        # –°–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ Image‚ÜíText
                        r1_img = mm_recall_at_k(sim_a.T, 1)
                        st.caption(f"Image‚ÜíText R@1: {r1_img:.3f}")

                        ab_result = None
                        df_boot_long = None

                        # ======== A/B —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±—É—Ç—Å—Ç—Ä—ç–ø–æ–º ========
                        if enable_ab and clip_model_b is not None and clip_proc_b is not None:
                            with torch.no_grad():
                                t_emb_b = clip_model_b.get_text_features(**clip_proc_b(text=texts, return_tensors="pt", padding=True, truncation=True)).cpu().numpy()
                                i_emb_b = clip_model_b.get_image_features(**clip_proc_b(images=imgs, return_tensors="pt")).cpu().numpy()
                            sim_b = mm_cosine_sim(t_emb_b, i_emb_b)

                            diffs_r1 = mm_bootstrap_metric_diff(sim_a.shape[0], mm_recall_at_k, sim_a, sim_b, iters=int(n_boot), k=1)
                            diffs_map = mm_bootstrap_metric_diff(sim_a.shape[0], mm_mean_average_precision, sim_a, sim_b, iters=int(n_boot))
                            diffs_ndcg = mm_bootstrap_metric_diff(sim_a.shape[0], mm_ndcg, sim_a, sim_b, iters=int(n_boot), k=10)

                            m_r1, m_map, m_ndcg = float(np.mean(diffs_r1)), float(np.mean(diffs_map)), float(np.mean(diffs_ndcg))
                            d1, d2, d3 = st.columns(3)
                            d1.metric("ŒîR@1 (B‚àíA)", f"{m_r1:+.3f}")
                            d2.metric("ŒîmAP (B‚àíA)", f"{m_map:+.3f}")
                            d3.metric("ŒînDCG@10 (B‚àíA)", f"{m_ndcg:+.3f}")

                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
                            try:
                                import pandas as _pd
                                df_boot = _pd.DataFrame({"ŒîR@1": diffs_r1, "ŒîmAP": diffs_map, "ŒînDCG@10": diffs_ndcg})
                                df_boot_long = df_boot.melt(var_name="metric", value_name="delta")
                                cols = st.columns(3)
                                if alt is not None:
                                    for ci, metric_name in enumerate(["ŒîR@1", "ŒîmAP", "ŒînDCG@10"]):
                                        chart = alt.Chart(df_boot[[metric_name]].rename(columns={metric_name: "delta"})).mark_bar().encode(
                                            x=alt.X("delta:Q", bin=alt.Bin(maxbins=40), title=metric_name),
                                            y=alt.Y("count():Q", title="Count")
                                        ).properties(height=180)
                                        cols[ci].altair_chart(chart, use_container_width=True)
                                elif plt is not None:
                                    fig, axes = plt.subplots(1, 3, figsize=(12, 3))
                                    axes[0].hist(diffs_r1, bins=30); axes[0].set_title("ŒîR@1")
                                    axes[1].hist(diffs_map, bins=30); axes[1].set_title("ŒîmAP")
                                    axes[2].hist(diffs_ndcg, bins=30); axes[2].set_title("ŒînDCG@10")
                                    for ax in axes: ax.grid(True, linestyle=":", alpha=0.4)
                                    st.pyplot(fig)
                            except Exception:
                                pass

                            # –≠–∫—Å–ø–æ—Ä—Ç CSV —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
                            if df_boot_long is not None:
                                csv_bytes = df_boot_long.to_csv(index=False).encode("utf-8")
                                st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –±—É—Ç—Å—Ç—Ä—ç–ø–∞ (CSV)", data=csv_bytes,
                                                   file_name="ab_bootstrap_distributions.csv", mime="text/csv")

                        # LLM-—Å–≤–æ–¥–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                        llm_summary = None
                        if use_llm_eval and llm_api_key and OpenAI is not None:
                            try:
                                client = OpenAI(api_key=llm_api_key, base_url=llm_api_base or None)
                                prompt = (
                                    "–°—É–º–º–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã retrieval-–æ—Ü–µ–Ω–∫–∏. –û–±—ä—è—Å–Ω–∏ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –∏ –≤—ã–≤–æ–¥—ã A/B-—Ç–µ—Å—Ç–∞ –∫—Ä–∞—Ç–∫–æ.\n"
                                    f"R@1={r1:.3f}, R@5={r5:.3f}, R@10={r10:.3f}, mAP={map_score:.3f}, nDCG@10={ndcg10:.3f}, MedRank={med_rank:.1f}.\n"
                                    f"A/B: {'–≤–∫–ª—é—á—ë–Ω' if enable_ab else '–≤—ã–∫–ª—é—á–µ–Ω'}."
                                )
                                resp = client.chat.completions.create(
                                    model=llm_model_name or "gpt-4o-mini",
                                    messages=[{"role": "user", "content": prompt}],
                                    temperature=0
                                )
                                llm_summary = resp.choices[0].message.content.strip()
                                st.info(llm_summary)
                            except Exception as e:
                                st.info(f"LLM-—Å–≤–æ–¥–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")

                        mm_add_history({
                            "type": "retrieval_eval",
                            "metrics": {"r1": r1, "r5": r5, "r10": r10, "map": map_score, "ndcg@10": ndcg10,
                                        "median_rank": med_rank, "img2text_r1": float(r1_img)},
                            "ab_enabled": bool(enable_ab),
                            "llm_summary": llm_summary
                        })
                        st.success("–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –ò—Å—Ç–æ—Ä–∏—é.")

    # ===================== 3) Image Generation Evaluation (approx) =====================
    with tab_gen:
        st.subheader("üé® –û—Ü–µ–Ω–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω–æ)")
        st.caption("CLIP-FID (–ø—Ä–∏–±–ª–∏–∂—ë–Ω–Ω—ã–π) –≤ CLIP-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ + —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ prompt‚Üíimage –ø–æ CLIPScore.")

        c1, c2, c3 = st.columns(3)
        with c1:
            zip_real = st.file_uploader("ZIP Real Images", type=["zip"], key="mm_gen_zip_real")
        with c2:
            zip_gen = st.file_uploader("ZIP Generated Images", type=["zip"], key="mm_gen_zip_gen")
        with c3:
            csv_prompts = st.file_uploader("CSV (prompt, gen_image)", type=["csv"], key="mm_gen_csv_prompts")

        if st.button("–û—Ü–µ–Ω–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é", type="primary", key="mm_gen_run"):
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            real_imgs, gen_imgs = [], []
            if zip_real:
                with zipfile.ZipFile(io.BytesIO(zip_real.read())) as zf:
                    for name in zf.namelist():
                        try:
                            with zf.open(name) as f:
                                real_imgs.append(Image.open(io.BytesIO(f.read())).convert("RGB"))
                        except Exception:
                            continue
            if zip_gen:
                bytes_gen = io.BytesIO(zip_gen.read())
                with zipfile.ZipFile(bytes_gen) as zf:
                    for name in zf.namelist():
                        try:
                            with zf.open(name) as f:
                                gen_imgs.append(Image.open(io.BytesIO(f.read())).convert("RGB"))
                        except Exception:
                            continue

            metrics = {}
            if real_imgs and gen_imgs:
                cfid = mm_clip_fid(clip_model_a, clip_proc_a, real_imgs, gen_imgs)
                metrics["CLIP-FID (approx)"] = cfid

            # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if csv_prompts is not None and zip_gen is not None:
                dfp = pd.read_csv(csv_prompts)
                gen_map = {}
                with zipfile.ZipFile(bytes_gen) as zf:
                    for name in zf.namelist():
                        try:
                            gen_map[name] = zf.read(name)
                        except Exception:
                            pass
                hyps, imgs = [], []
                for _, row in dfp.iterrows():
                    prompt = str(row.get("prompt", ""))
                    gname = str(row.get("gen_image", ""))
                    if gname in gen_map:
                        try:
                            img = Image.open(io.BytesIO(gen_map[gname])).convert("RGB")
                        except Exception:
                            continue
                        imgs.append(img)
                        hyps.append(prompt)
                if imgs:
                    clipscore_ti = mm_clipscore(clip_model_a, clip_proc_a, hyps, imgs)
                    metrics["CLIPScore (prompt‚Üíimage)"] = clipscore_ti

            if metrics:
                cols = st.columns(len(metrics))
                for i, (k, v) in enumerate(metrics.items()):
                    cols[i].metric(k, f"{v:.3f}")
                mm_add_history({"type": "imagegen_eval", "metrics": metrics})
                st.success("–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –ò—Å—Ç–æ—Ä–∏—é.")
            else:
                st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –º–µ—Ç—Ä–∏–∫.")

    # ===================== 4) VQA / Reasoning Eval (simple) =====================
    with tab_vqa:
        st.subheader("‚ùì VQA / Reasoning (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)")
        st.caption("Exact match –ø–æ –æ—Ç–≤–µ—Ç—É + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π LLM-—Å—É–¥—å—è –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è.")

        c1, c2, c3 = st.columns(3)
        with c1:
            csv_vqa = st.file_uploader("CSV (image, question, answer)", type=["csv"], key="mm_vqa_csv")
        with c2:
            zip_vqa = st.file_uploader("ZIP images", type=["zip"], key="mm_vqa_zip")
        with c3:
            max_samples = st.number_input("–ú–∞–∫—Å. –ø—Ä–∏–º–µ—Ä–æ–≤", 1, 2000, 200, key="mm_vqa_max")

        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å VQA", type="primary", key="mm_vqa_run"):
            if not (csv_vqa and zip_vqa):
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏ ZIP —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.")
            else:
                df = pd.read_csv(csv_vqa)
                correct, total = 0, 0
                examples = []
                with zipfile.ZipFile(io.BytesIO(zip_vqa.read())) as zf:
                    for i, row in df.head(int(max_samples)).iterrows():
                        fname = str(row.get("image", ""))
                        q = str(row.get("question", ""))
                        ans = str(row.get("answer", "")).strip().lower()
                        if not fname or fname not in zf.namelist():
                            continue
                        with zf.open(fname) as f:
                            img = Image.open(io.BytesIO(f.read())).convert("RGB")
                        pred = mm_blip_vqa_answer(blip_vqa_model, blip_vqa_proc, img, q).strip().lower()
                        total += 1
                        ok = int(pred == ans)
                        correct += ok
                        if len(examples) < 16:
                            examples.append({"image": fname, "q": q, "gt": ans, "pred": pred, "ok": ok})

                acc = (correct / total) if total else 0.0
                st.metric("Accuracy (exact match)", f"{acc:.3f}")

                # LLM-—Å—É–¥—å—è (—Å–µ–º–∞–Ω—Ç–∏–∫–∞)
                if use_llm_eval and llm_api_key and OpenAI is not None and examples:
                    try:
                        client = OpenAI(api_key=llm_api_key, base_url=llm_api_base or None)
                        agree = 0
                        with st.expander("ü§ñ LLM-—Å—É–¥—å—è (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)"):
                            for ex in examples:
                                prompt = (
                                    "–ü—Ä–æ–≤–µ—Ä—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞. –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ: YES –∏–ª–∏ NO.\n"
                                    f"–í–æ–ø—Ä–æ—Å: {ex['q']}\n–ò—Å—Ç–∏–Ω–∞: {ex['gt']}\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {ex['pred']}"
                                )
                                resp = client.chat.completions.create(
                                    model=llm_model_name or "gpt-4o-mini",
                                    messages=[{"role": "user", "content": prompt}],
                                    temperature=0
                                )
                                verdict = resp.choices[0].message.content.strip().upper()
                                st.write(f"{ex['image']} ‚Üí {verdict}")
                                if verdict.startswith("Y"):
                                    agree += 1
                        st.caption(f"LLM-—Å–æ–≥–ª–∞—Å–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö: {agree}/{len(examples)}")
                    except Exception as e:
                        st.info(f"LLM-—Å—É–¥—å—è –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

                mm_add_history({"type": "vqa_eval", "accuracy": float(acc), "samples": int(total)})
                st.success("–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –ò—Å—Ç–æ—Ä–∏—é.")

    # ===================== 5) –ò—Å—Ç–æ—Ä–∏—è =====================
    with tab_hist:
        st.subheader("üóÇÔ∏è –ò—Å—Ç–æ—Ä–∏—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
        if st.session_state["mm_history"]:
            st.json(st.session_state["mm_history"][-10:])
            data = json.dumps(st.session_state["mm_history"], ensure_ascii=False, indent=2).encode("utf-8")
            st.download_button("–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é (JSON)", data=data, file_name="mm_history.json", mime="application/json")
        else:
            st.info("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –æ—Ü–µ–Ω–æ–∫ –≤—ã—à–µ.")
